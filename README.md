# KNNDemo
1、K-近邻算法（KNN）
其原理为在一个样本空间中，有一些已知分类的样本，当出现一个未知分类的样本，则根据距离这个未知样本最近的k个样本来决定。
举例：爱情电影和动作电影，它们中都存在吻戏和动作，出现一个未知分类的电影，将根据以吻戏数量和动作数量建立的坐标系中距离未知分类所在点的最近的k个点来决定。

2、算法实现步骤
（1）计算所有点距离未知点的欧式距离
（2）对所有点进行排序
（3）找到距离未知点最近的K个点
（4）计算这K个点所在分类出现的频率
（5）统计K个样本点中出现频率最高的类别标签

优点:
1. 原理简单，容易理解，容易实现
2. 重新训练代价较低
3. 时间、空间复杂度取决于训练集

缺点:
1. KNN属于lazy-learning算法，得到结果及时性差
2. k值对结果影响大（试想一下k=1和k=N的极端情况）
3. 样本点较多时，计算量较大
4. 相对于决策树，结果可解释性不强
